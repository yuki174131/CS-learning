仮想記憶はメモリの抽象化技術であり、ページング技術によりメインメモリとストレージ間の移動をページ単位で行うことが可能になっている。この結果、完全にメモリ上に存在しないプロセスを実行することができた。
仮想記憶では、記憶領域を完全に抽象化し、開発者が直接触れる仮想記憶領域と、実際にデータが格納される物理的な記憶領域を分離する。この分離によって、メモリ管理を OS に一任することが可能になる。

さらに、プロセスごとに仮想メモリ空間を設定することで、各プロセスのメモリ空間を完全に分離することができるという特徴もあります。この分離によって、各プロセスが他のプロセスのメモリ空間に影響を及ぼすことなく独立して動作することが可能になる。
その一方で、カーネルや共有ライブラリなど共有が必要な部分については、ページテーブルを用いて同じ物理メモリアドレスを参照することで、全プロセスで共有することができる。この機能によって、効率的にメモリリソースを共用することが可能になる。
https://gyazo.com/41fdcd7d2c70452d3e5d9f59b84973ff

以下のような構造によって、プロセスの仮想メモリアドレス空間は各種のデータと命令が効率的に管理され、アプリケーションの実行が支えられている。
各領域は特定の目的と役割を果たし、プロセス間の独立性やセキュリティなどを確保している。

基本的なメモリアドレス空間は、以下のような領域に分けられます。

カーネル領域
カーネル領域はオペレーティングシステムが管理する部分で、ハードウェアやシステムリソースへのアクセスを制御する。ユーザープロセスからは直接アクセスすることができない保護された領域。

スタック領域
スタックは、関数の呼び出しと戻り値の管理、ローカル変数の保存などに使われる領域。データは後入れ先出し（LIFO）の構造で格納されるため、任意の位置での確保と解放はできない。

空き領域
空き領域はプロセスの動的なメモリニーズに応じて変動する。スタック領域が上から、ヒープ領域が下から拡張されていく場合が一般的。

ヒープ領域
ヒープは動的メモリ割り当てを行う領域で、C 言語の malloc() などによって管理される。必要に応じてメモリを確保し、不要になったら解放することができる。

BSS（Block Started by Symbol）領域
BSS 領域は、プログラム内の静的変数またはグローバル変数のうち、初期化されていない変数や 0 で初期化された変数が格納される。

データ領域
データ領域は、静的変数やグローバル変数のうち、0 以外で初期化された変数が保存される。プログラムの実行中に変更可能な値がここに格納されることが多い。

テキスト領域
テキスト領域は機械語に翻訳されたプログラムコードが格納される部分。この領域には命令が保存され、一般に書き換えることができない読み取り専用の領域となっている。


デマンドページング
ページが必要とされる際にのみ、補助記憶装置から物理メモリへロードするというメモリ管理の技法。この手法では、必要になるページだけが物理メモリにロードされ、全体のメモリ利用効率が向上する。
ページが物理メモリに存在せず、アクセスされる必要がある場合、ページフォールトが発生する。ページフォールトとは、システムが必要なページが物理メモリ上に存在しないことを検出した際の割り込みのことで、デマンドページングの一環として動作する。
ページフォールトが発生すると、対象のページが補助記憶装置から物理メモリ上にロードされる操作が行われ、問題が解決される。

この過程では、ページインとページアウトという概念が重要。ページインは、補助記憶装置から物理メモリにページをロードする操作で、ページフォールトが発生したときに実行される。
一方、ページアウトは、物理メモリから補助記憶装置にページを戻す操作で、これによりメモリの空間を効率的に利用することができる。
この概念を具体的な例で考えると、ページ 0 が物理メモリ上に存在していれば、そのページはすぐにアクセス可能。ページ 1 が物理メモリ上に存在しない場合、ページフォールトが発生し、
デマンドページングによって補助記憶装置からページ 1 を物理メモリ上にロードする。特定のページを使用しない場合、そのページを物理メモリにロードする必要がないため、メモリの効率的な利用が可能になる。

このように、デマンドページングとページフォールトの概念は互いに関連しており、メモリ管理における効率と効果を高める役割を果たしている。

参照の局所性
デマンドページングに関しては、命令の実行ごとに毎回数ページのメモリをストレージから読み込むという懸念があるかもしれませんが、実際にはそのような場合は稀。
これはプログラムの実行において、参照の局所性という特徴が影響している。参照の局所性とは、プログラムが一度参照したメモリ位置に対して、短い時間内に再びアクセスする傾向のことを指し、
この性質によって、プログラムが常に新しいページを要求するという事態は極めてまれとなるため、デマンドページングは効果的に動作する。

ページングとスワッピング
また、デマンドページングとスワッピングという二つのメモリ管理の技法は、しばしば似た概念として扱われることがあるが、実際には異なる点があります。スワッピングは、プロセス全体をメインメモリとストレージ間で移動する操作を指す。
これに対して、デマンドページングやページングは、ページ単位でのロードや置き換えを行う。
つまり、スワッピングはプロセス全体を対象とする一方で、ページングはより細かい単位であるページに焦点を当てる操作で、それぞれの用途と最適化の点で異なる役割を果たしている。

ページングは、プロセスに非連続のアドレス空間を割り当てるメモリ管理手法であり、外部断片化の問題を回避する。主記憶は固定サイズのブロックであるフレームに分割され、プロセスの論理メモリも同様にページと呼ばれる固定サイズのブロックに分割される。
ページとフレームのサイズはハードウェアによって定義される。ページテーブルは各ページの基本アドレスを含み、ページ番号とページオフセットを組み合わせてメインメモリ内のページのアドレスを生成する。
スワッピングは、メインメモリが完全に埋まっているときに、他のプロセスが実行できるようにメインメモリからバックストアへプロセスを交換する手法。スワッピングは、複数のプロセスを並行して実行するのに役立つが、パフォーマンスに影響を及ぼすことがある。


ページフォールト
ページフォールト（page fault）という割り込みは、システムがメモリ上に存在しないページへアクセスしようとした際に発生する。ページフォールト自体はエラーではないという点が重要で、しばしば誤解されることがある。
ページフォールトが発生したとき、オペレーティングシステムは対象となるページを補助記憶装置からメインメモリに取り込み、要求された操作を続行する。この過程はデマンドページングの一部として通常の動作であり、エラーではない。

しかし、アクセス制限のないアドレスへアクセスしようとしたり、要求されたデータが存在しなかったりした場合には、これは真のエラー状態となる。このような状況では、システムは通常、該当のプロセスを強制終了させる必要がある。
さらに、ページフォルトが極端に頻繁に発生し、処理がほとんど進まない状態をスラッシングと呼ぶ。スラッシングは、システムがページフォルトの処理に忙殺され、実際の作業がほとんど行われない状況を指し、これはシステムのパフォーマンスに深刻な影響を及ぼす可能性がある。
スラッシングが発生すると、メモリ管理の調整やリソースの再割り当てなど、適切な対策を講じる必要がある。


ページ置換アルゴリズム
利用可能なメモリが少なくなると、OS は、この問題を解決するために、スワッピングとページ置換というテクニックを組み合わせて使用する。これにより、必要なメモリ空間を確保し、プロセスをスムーズに実行することが可能になる。
メインメモリは、単にページの保持だけではなく、I/O バッファにもかなりの割合を使用する。したがって、ページ置換のアルゴリズムの選択は、システムのパフォーマンスに大きな影響を及ぼす。

FIFO アルゴリズム
FIFO アルゴリズムは、ページの置換プロセスにおいて最初にページインしたページから順番に交換していく方法。このアルゴリズムでは、メモリ内の全ページを保持するキューが作られる。
そのキューの先頭からページが交換され、新しいページがメモリにロードされるたびにキューの最後尾に挿入される。この方法は、その構造がシンプルであるため、理解しやすくプログラミングも容易。
しかしこの方法には注意点もある。最初にページインされ、その後頻繁に使用されるページが、最終的には削除される可能性があるため、この点を考慮する必要がある。これは、特定のユースケースにおいて効率が低下する可能性があるため、慎重な分析と適切な選択が必要。
https://gyazo.com/6875ffd501f338c1a7dda1d83fc9ee6f

OPT アルゴリズム
OPT アルゴリズムは、未来を含めて最も長い間使用されていないページから入れ替えるという戦略を採用している。この特性により、ページ置換において最もページフォールトが低いとされる理想的なアルゴリズムといえる。
このアルゴリズムは、ページフォールトを最小限に抑えることができるため、理論的には非常に効率的なものとなる。
しかし、OPT アルゴリズムには重要な課題がある。それは、どのページが将来的に最も使われないかを正確に予知する必要がある。この予知は、事前にページの使用パターンを完全に知っている場合にのみ可能であり、現実的なシステムでは非常に困難な課題となる。
そのため、このアルゴリズムは実際のシステムでの利用が限定されることが一般的であり、他のページ置換アルゴリズムとの比較やベンチマークとして主に扱われることが多い。
https://gyazo.com/b0d5fce30990ad1444632319a27145e7

LRU アルゴリズム
LRU アルゴリズムは、メモリにロードされたページのうち、最も長い間参照されていないページから交換する手法。OPT アルゴリズムが未来のページ使用予測を必要とするのに対し、LRU アルゴリズムは、これまでのページ使用の歴史に基づく仮定を利用する。
具体的には、これまでに使われていなかったページは今後も使われないであろうという仮定を基にしている。この近似手法が、実際のシステムにおいてより現実的な選択肢として LRU を使う理由となっている。
LRU と FIFO の主な違いは、交換の基準になる時間の考慮の仕方。FIFO はメモリにロードされた時間を基準にしますが、LRU は最後に使用された時間を基準にする。これにより、LRU は現在のページの使用状況により密接に連動した挙動を示し、システムの効率を向上させることができる。
しかし、LRU アルゴリズムにも実装コストが高いという問題がある。これは、ページが参照されるたびに使用頻度を記録するデータ構造を更新しなければならないため。このプロセスは、高い計算リソースと高機能なハードウェアの支援を必要とする場合が多く、この点を考慮する必要がある。
https://gyazo.com/682cda8cf0a0d8b22209d6fcba78a0e7

Additional-Reference-Bits アルゴリズム
このアルゴリズムは、ページテーブルに記録されている参照ビットを使用するもの。LRU アルゴリズムの実装は特別なハードウェアが必要であるため、より現実的で実用的な代替手段として、このアルゴリズムが検討されることがある。
参照ビットはページングテーブルの各エントリに関連付けられており、プロセスが実行される際には初期状態では 0 に設定されている。ページが参照されると、対応する参照ビットが 1 に書き換えられます。このシンプルなビット操作を利用して、ページが参照されたかどうかを効率的に追跡することができる。
さらに進んだ応用として、参照ビットを 8 列などのビット列に拡張することで、期間ごとのページ参照の順序情報を記録することも可能。この拡張によって、ページの更新時期をある程度把握し、ページの交換の判断をより精緻に行うことができる。
ただし、このアルゴリズムには注意すべき点もある。ビット列は必ずしも一意であることが保証されていないため、同じビット列が複数のページに対応する可能性がある。このため、精緻なページ交換の判断が必要になる場合、このビット列の解釈には慎重さが求められることがある。

Second Chance アルゴリズム
このアルゴリズムは、参照ビットを拡張せず、1 ビットのみを利用するシンプルなページ置換のアプローチです。参照ビットが 0 の場合、そのページは交換の対象とされます。一方、参照ビットが 1 であれば、FIFO に基づいてページ置換が行われる。
ページの管理には、FIFO と同様に連結リスト構造が使用される。特に、この連結リストが循環連結リストで実装されたものを Clock アルゴリズムと呼ぶこともある。循環連結リストの構造は、リストの末尾が先頭に再接続されているため、時計のように見えることからこの名前が付けられた。
このアルゴリズムの重要な特性として、参照ビットが全て 1 であった場合には、FIFO と全く同じ方法になる点が挙げられる。セカンドチャンスアルゴリズムは、その名前が示す通り、ページに「第二のチャンス」を与えることができるため、一度使用されたページがすぐに交換されることを防ぐことができる。
参照ビットが 1 であれば、ページが最初の交換から免れ、次の交換の機会を得ることができる。

Enhanced Second Chance アルゴリズム
このアルゴリズムは、参照ビットを拡張して、複数ビットに意味を持たせて利用する。一般の Second Chance アルゴリズムや Clock アルゴリズムでは、参照ビットのみを使用していましたが、Enhanced Second-Chance アルゴリズムでは、1 ビット追加することで、ページの分類が 4 つのクラスに可能になる。

(0,0): 最近使用されていない上に変更されていないページ
(0,1): 最近使用されていないが変更されたページ
(1,0): 最近使用されたが変更されていないページ
(1,1): 最近使用された上に変更されているページ
この分類により、ページ交換の優先度をより精緻に決定することができます。特に、変更されていないページと変更されたページを区別することで、I/O の操作を減らすことが可能。変更されていないページはディスクへの書き戻しが不要であるため、この分類による効率化が可能。
構造自体は、Clock アルゴリズムと同様の循環連結リストであり、その管理は比較的単純です。しかし、この方法の場合、置換する適切なページを見つけるまでに数回のスキャンを要する可能性があるため、その点には注意が必要。このスキャンのコストが、アルゴリズムの全体的な効率にどう影響するかを検討する必要がある。










